{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbYEdOgD5r5twAkgVKaRux"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-EAFJsM6Krza","executionInfo":{"status":"ok","timestamp":1690559531587,"user_tz":240,"elapsed":543765,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"0733d464-5860-4071-cd3c-68626ce10fd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import drive\n","import os\n","import librosa\n","from librosa.feature import spectral_bandwidth\n","\n","# Mount Google Drive for access\n","drive.mount('/content/drive')\n","\n","def extract_5sec_chunks(audio_array: np.ndarray, window_size_s: float = 8.0, hop_size_s: float = 4.0, sample_rate=16000) -> np.ndarray:\n","    frame_length = int(window_size_s * sample_rate)\n","    frame_step = int(hop_size_s * sample_rate)\n","    framed_audio = tf.signal.frame(audio_array, frame_length, frame_step, pad_end=False)\n","    return framed_audio\n","\n","def spectral_bandwidth_feature(audio_array, sample_rate=22050, n_fft=2048, p=2):\n","    spec_bandwidth = spectral_bandwidth(y=audio_array, sr=sample_rate, n_fft=n_fft, p=p)\n","    return spec_bandwidth.T  # Transpose the array to have shape (n_samples, n_features)\n","\n","def spectral_bandwidth_chunks(dataframe):\n","    y = []\n","    X = []\n","\n","    for i, row in dataframe.iterrows():\n","        label = row['primary_label']\n","        tensor_5sec = row['audio_chunks']\n","\n","        for each in tensor_5sec:\n","            y.append(label)\n","            each = np.array(each)\n","            X_spec_bandwidth = spectral_bandwidth_feature(each)  # Compute Spectral Bandwidth\n","            X_spec_bandwidth = X_spec_bandwidth.reshape(1, -1)  # Reshape to have a single sample dimension\n","            X.append(X_spec_bandwidth)\n","\n","    assert len(y) == len(X)\n","\n","    y = np.array(y)\n","    X = np.concatenate(X, axis=0)\n","\n","    return X, y\n","\n","dataset_path = '/content/drive/MyDrive/207-Project/notebooks/RG/3_species/'\n","metadata_path = os.path.join(dataset_path, \"train_val.csv\")\n","metadata_df = pd.read_csv(metadata_path)\n","\n","train_df = metadata_df[metadata_df['data'] == 'train'].copy()\n","validate_df = metadata_df[metadata_df['data'] == 'val'].copy()\n","\n","train_audios = []\n","for filename in train_df['filename_npy']:\n","    audio = np.load('/content/drive/MyDrive/207-Project/data/train/librosa_loaded/' + filename)\n","    train_audios.append(audio)\n","\n","val_audios = []\n","for filename in validate_df['filename_npy']:\n","    audio = np.load('/content/drive/MyDrive/207-Project/data/train/librosa_loaded/' + filename)\n","    val_audios.append(audio)\n","\n","train_chunks = [extract_5sec_chunks(audio) for audio in train_audios]\n","val_chunks = [extract_5sec_chunks(audio) for audio in val_audios]\n","\n","train_df['audio_chunks'] = train_chunks\n","validate_df['audio_chunks'] = val_chunks\n","\n","X_train, y_train = spectral_bandwidth_chunks(train_df)\n","X_val, y_val = spectral_bandwidth_chunks(validate_df)\n","\n","X_train_list = X_train.tolist()\n","y_train_list = y_train.tolist()\n","X_val_list = X_val.tolist()\n","y_val_list = y_val.tolist()\n","\n","with open('/content/drive/MyDrive/My-207/X_train_bandwidth.json', 'w') as file:\n","    json.dump(X_train_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_train_bandwidth.json', 'w') as file:\n","    json.dump(y_train_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/X_val_bandwidth.json', 'w') as file:\n","    json.dump(X_val_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_val_bandwidth.json', 'w') as file:\n","    json.dump(y_val_list, file)\n"]}]}