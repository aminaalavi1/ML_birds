{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7rytC7PT-t-","executionInfo":{"status":"ok","timestamp":1690432860403,"user_tz":240,"elapsed":1113,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"507381a2-266e-43da-bb77-54f3306217a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import json\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.utils import to_categorical\n","import librosa\n","from google.colab import drive\n","import os\n","\n","# Mount Google Drive for access\n","drive.mount('/content/drive')\n","\n","from sklearn.preprocessing import MinMaxScaler\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","source":["# Load data\n","with open('/content/drive/MyDrive/My-207/X_train_centroid.json', 'r') as file:\n","    X_train_list = json.load(file)\n","    X_train_centroid = np.array(X_train_list)\n","\n","with open('/content/drive/MyDrive/My-207/y_train_centroid.json', 'r') as file:\n","    y_train_list = json.load(file)\n","    y_train = np.array(y_train_list)\n","\n","# Load data from JSON files validation with centroid features\n","with open('/content/drive/MyDrive/My-207/X_val_centroid.json', 'r') as file:\n","    X_val_list = json.load(file)\n","    X_val_centroid = np.array(X_val_list)\n","\n","with open('/content/drive/MyDrive/My-207/y_val_centroid.json', 'r') as file:\n","    y_val_list = json.load(file)\n","    y_val = np.array(y_val_list)\n"],"metadata":{"id":"kQAPQEvUKT7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data normalization\n","scaler = StandardScaler()\n","\n","# Fit and transform the training data\n","X_train_centroid_normalized = scaler.fit_transform(X_train_centroid)\n","\n","# Transform the validation data using the scaler parameters from the training data\n","X_val_centroid_normalized = scaler.transform(X_val_centroid)\n","\n","# Convert string labels to numerical labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# One-hot encode the labels for LSTM\n","y_train_onehot = to_categorical(y_train_encoded)\n","y_val_onehot = to_categorical(y_val_encoded)\n","\n","# Save the label encoder for later use\n","label_encoder_path = \"label_encoder.pkl\"\n","import joblib\n","joblib.dump(label_encoder, label_encoder_path)\n","\n","# Reshape the data for LSTM (add additional dimension for time steps)\n","X_train_lstm = X_train_centroid_normalized.reshape(X_train_centroid_normalized.shape[0], X_train_centroid_normalized.shape[1], 1)\n","X_val_lstm = X_val_centroid_normalized.reshape(X_val_centroid_normalized.shape[0], X_val_centroid_normalized.shape[1], 1)\n","\n"],"metadata":{"id":"5E2cUgMZKE_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build LSTM model topology for centroid features\n","model = tf.keras.Sequential([\n","    LSTM(128, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True),\n","    LSTM(64),\n","    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n","])\n","\n","\n","\n","\n"],"metadata":{"id":"4-DmdlWSKbze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Summary of the model\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-Z-OKTjKjkM","executionInfo":{"status":"ok","timestamp":1690432994243,"user_tz":240,"elapsed":143,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"99dc2e7f-a3bf-42d4-f6cc-4a25aa6abf45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 251, 128)          66560     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                49408     \n","                                                                 \n"," dense (Dense)               (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 116,163\n","Trainable params: 116,163\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Train the model\n","# Early stopping callback\n","early_stopping = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n","\n","# Train the model with early stopping\n","history = model.fit(X_train_lstm, y_train_onehot, validation_data=(X_val_lstm, y_val_onehot),\n","                    batch_size=32, epochs=100, callbacks=[early_stopping])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyGppBP0KmTG","executionInfo":{"status":"ok","timestamp":1690433944004,"user_tz":240,"elapsed":945179,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"8ecbc07d-fb0e-43ff-e718-800d1ab7f81a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","143/143 [==============================] - 102s 642ms/step - loss: 1.0590 - accuracy: 0.4536 - val_loss: 1.1556 - val_accuracy: 0.2739\n","Epoch 2/100\n","143/143 [==============================] - 85s 599ms/step - loss: 1.0336 - accuracy: 0.4852 - val_loss: 1.1105 - val_accuracy: 0.3983\n","Epoch 3/100\n","143/143 [==============================] - 84s 589ms/step - loss: 1.0057 - accuracy: 0.5183 - val_loss: 1.1206 - val_accuracy: 0.4129\n","Epoch 4/100\n","143/143 [==============================] - 84s 587ms/step - loss: 1.0521 - accuracy: 0.4692 - val_loss: 1.1225 - val_accuracy: 0.3709\n","Epoch 5/100\n","143/143 [==============================] - 84s 587ms/step - loss: 1.0249 - accuracy: 0.5041 - val_loss: 1.1237 - val_accuracy: 0.3541\n","Epoch 6/100\n","143/143 [==============================] - 84s 586ms/step - loss: 1.0170 - accuracy: 0.5168 - val_loss: 1.0808 - val_accuracy: 0.4028\n","Epoch 7/100\n","143/143 [==============================] - 85s 591ms/step - loss: 1.0444 - accuracy: 0.4533 - val_loss: 1.1509 - val_accuracy: 0.3148\n","Epoch 8/100\n","143/143 [==============================] - 84s 587ms/step - loss: 1.0435 - accuracy: 0.4722 - val_loss: 1.1924 - val_accuracy: 0.3081\n","Epoch 9/100\n","143/143 [==============================] - 84s 585ms/step - loss: 1.0449 - accuracy: 0.4722 - val_loss: 1.1821 - val_accuracy: 0.3440\n","Epoch 10/100\n","143/143 [==============================] - 84s 588ms/step - loss: 1.0302 - accuracy: 0.4839 - val_loss: 1.1289 - val_accuracy: 0.3669\n","Epoch 11/100\n","143/143 [==============================] - 85s 591ms/step - loss: 1.0242 - accuracy: 0.4830 - val_loss: 1.1541 - val_accuracy: 0.3686\n"]}]},{"cell_type":"code","source":["\n","# Plot the training and validation loss\n","plt.figure(figsize=(6, 4))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot the training and validation accuracy\n","plt.figure(figsize=(6, 4))\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"HqhWCrz8Kpnx"},"execution_count":null,"outputs":[]}]}