{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzI51BzbSBsKttdWgiUYIp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7rytC7PT-t-","executionInfo":{"status":"ok","timestamp":1690909240649,"user_tz":240,"elapsed":117777,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"bd6ada84-ec17-4694-a86d-34300d47513c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Standard libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import librosa\n","from google.colab import drive\n","import os\n","import random\n","\n","from librosa import load as lload\n","from librosa.feature import mfcc\n","from librosa.feature.inverse import mfcc_to_audio\n","\n","# Mount Google Drive for access\n","drive.mount('/content/drive')\n","\n","# Base directory path\n","base_directory_path = '/content/drive/MyDrive/207-Project/notebooks/RG/3_species/librosa_loaded_sr16000/'\n","\n","# Augmentation functions\n","def add_noise(data):\n","    noise = np.random.randn(len(data))\n","    data_noise = data + 0.005 * noise\n","    return data_noise\n","\n","def shift(data):\n","    return np.roll(data, 1600)\n","\n","# def pitch(data, sample_rate):\n","#     return librosa.effects.pitch_shift(data, sample_rate, np.random.randint(-5, 5))\n","\n","def change_volume(data):\n","    return data * np.random.uniform(low=0.75, high=1.25)\n","\n","def augment(data, sample_rate):\n","    choice = np.random.choice([1, 2, 3])\n","    if choice == 1:\n","        return add_noise(data)\n","    elif choice == 2:\n","        return shift(data)\n","    elif choice == 3:\n","        return change_volume(data)\n","    else:\n","        return data\n","\n","# Function to extract 5-second  chunks from audio\n","def extract_5sec_chunks(\n","    audio_array: np.ndarray,\n","    window_size_s: float = 5.0,\n","    hop_size_s: float = 2.5, #(with overlap)\n","    sample_rate=16000,\n","    augment_ratio=0.3\n",") -> np.ndarray:\n","    # Augment data if random value is less than augment_ratio\n","    if random.random() < augment_ratio:\n","        audio_array = augment(audio_array, sample_rate)\n","\n","    frame_length = int(window_size_s * sample_rate)\n","    frame_step = int(hop_size_s * sample_rate)\n","    framed_audio = tf.signal.frame(audio_array, frame_length, frame_step, pad_end=False)\n","\n","    return framed_audio\n","\n"]},{"cell_type":"code","source":["# Load metadata\n","dataset_path = '/content/drive/MyDrive/207-Project/notebooks/RG/3_species/'\n","metadata_path = os.path.join(dataset_path, \"train_val.csv\")\n","metadata_df = pd.read_csv(metadata_path)\n","\n","# Create a dictionary to map filenames to labels\n","labels_dict = metadata_df.set_index('filename_npy')['primary_label'].to_dict()\n","\n","# Get unique filenames from the metadata\n","filenames = set(base_directory_path + '/' + metadata_df['filename_npy'].unique())\n","\n","# Split train and validation data\n","train_df = metadata_df[metadata_df['data'] == 'train']\n","validate_df = metadata_df[metadata_df['data'] == 'val']\n","\n","# Load all train audio data one time\n","train_audios = []\n","for filename in train_df['filename_npy']:\n","    audio = np.load('/content/drive/MyDrive/207-Project/data/train/librosa_loaded/' + filename)\n","    train_audios.append(audio)\n","\n","# Load all validate audio data one time\n","val_audios = []\n","for filename in validate_df['filename_npy']:\n","    audio = np.load('/content/drive/MyDrive/207-Project/data/train/librosa_loaded/' + filename)\n","    val_audios.append(audio)\n","\n","#Initialize an empty list to store the chunk data for training data\n","train_chunks = []\n","for audio in train_audios:\n","    train_chunks.append(extract_5sec_chunks(audio))\n","\n","#Initialize an empty list to store the chunk data for VALIDATION data\n","val_chunks = []\n","for audio in val_audios:\n","    val_chunks.append(extract_5sec_chunks(audio))\n","\n","#add chunks to training data\n","train_df['audio_chunks'] = train_chunks\n","\n","#add chunks to validation data\n","validate_df['audio_chunks'] = val_chunks\n","\n","#add chunks to trainig data\n","train_df['audio_chunks'] = train_chunks\n","train_df.head()\n","train_df = train_df.sample(frac=1, random_state=1234)\n","\n","#add chunks to validation data\n","validate_df['audio_chunks'] = val_chunks\n","validate_df.head()\n","validate_df = validate_df.sample(frac=1, random_state=1234)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_g1Xmh5Uwk7m","executionInfo":{"status":"ok","timestamp":1690909507863,"user_tz":240,"elapsed":267221,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"68e8bcff-44e6-4480-f7c7-c99c8b275379"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-bcaa412a725c>:39: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_df['audio_chunks'] = train_chunks\n","<ipython-input-2-bcaa412a725c>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  validate_df['audio_chunks'] = val_chunks\n","<ipython-input-2-bcaa412a725c>:45: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_df['audio_chunks'] = train_chunks\n","<ipython-input-2-bcaa412a725c>:50: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  validate_df['audio_chunks'] = val_chunks\n"]}]},{"cell_type":"code","source":["# drop the samples with less than 8 seconds in duration\n","metadata_df = metadata_df[metadata_df['duration_secs_32000'] >= 8]"],"metadata":{"id":"9i8IYz_Z-0FT","executionInfo":{"status":"ok","timestamp":1690909507869,"user_tz":240,"elapsed":48,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def mfcc_chunks(dataframe: pd.DataFrame, sample_rate=16000, n_mfcc=13, n_fft=2048) -> tuple[np.ndarray, np.ndarray]:\n","    y = []\n","    X = []\n","    continents = []\n","\n","    for i, row in dataframe.iterrows():\n","      label = row['primary_label']\n","      tensor_5sec = row['audio_chunks']\n","      continent = row['continent']\n","\n","\n","      for each in tensor_5sec:\n","        y.append(label)\n","        continents.append(continent)\n","        each = np.array(each)\n","        X_mfcc = mfcc(y=each, sr=sample_rate)\n","        X.append(X_mfcc)\n","\n","    assert len(y) == len(X)\n","    assert len(y) == len(continents)\n","\n","    y = np.array(y)\n","    X = np.array(X)\n","    continents = np.array(continents)\n","\n","    return X, y, continents\n","\n"],"metadata":{"id":"H9n6Dl8n05Kw","executionInfo":{"status":"ok","timestamp":1690909507870,"user_tz":240,"elapsed":36,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","#convert to X and y\n","X_train, y_train,  train_continents = mfcc_chunks(train_df)\n","\n","#convert to X and y\n","X_val, y_val , val_continents= mfcc_chunks(validate_df)\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_val shape:\", X_val.shape)\n","print(\"y_val shape:\", y_val.shape)\n","print(train_df['primary_label'].unique())\n","\n","# Save data to JSON files\n","X_train_list = X_train.tolist()\n","y_train_list = y_train.tolist()\n","X_val_list = X_val.tolist()\n","y_val_list = y_val.tolist()\n","train_cont  = train_continents.tolist()\n","val_cont = val_continents.tolist()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"te6zOck9zBpe","executionInfo":{"status":"ok","timestamp":1690909829097,"user_tz":240,"elapsed":220650,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"d46beeb5-2693-4a8e-cf73-e54510ca825a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (7889, 20, 157)\n","y_train shape: (7889,)\n","X_val shape: (3121, 20, 157)\n","y_val shape: (3121,)\n","['comsan' 'eaywag1' 'barswa']\n"]}]},{"cell_type":"code","source":["import json\n","# Save data to JSON files\n","with open('/content/drive/MyDrive/My-207/X_train_mfcc_aug.json', 'w') as file:\n","    json.dump(X_train_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_train_mfcc_aug.json', 'w') as file:\n","    json.dump(y_train_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/X_val_mfcc_aug.json', 'w') as file:\n","    json.dump(X_val_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_val_mfcc_aug.json', 'w') as file:\n","    json.dump(y_val_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/X_val_cont.json', 'w') as file:\n","    json.dump(train_cont, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_val_cont.json', 'w') as file:\n","    json.dump(val_cont, file)\n"],"metadata":{"id":"85hCnGi22NZw","executionInfo":{"status":"ok","timestamp":1690910007329,"user_tz":240,"elapsed":88251,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IoRzqKOJzChF","executionInfo":{"status":"aborted","timestamp":1690909507873,"user_tz":240,"elapsed":27,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}}},"execution_count":null,"outputs":[]}]}