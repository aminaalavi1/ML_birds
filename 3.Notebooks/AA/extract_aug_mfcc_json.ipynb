{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkBNND8auJJxqF72lgCd+a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7rytC7PT-t-","executionInfo":{"status":"ok","timestamp":1690854938884,"user_tz":240,"elapsed":832,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"43e1e3f2-e3e8-484b-954e-268f5cd31ee6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Standard libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","import librosa\n","from google.colab import drive\n","import os\n","import random\n","\n","from librosa import load as lload\n","from librosa.feature import mfcc\n","from librosa.feature.inverse import mfcc_to_audio\n","\n","# Mount Google Drive for access\n","drive.mount('/content/drive')\n","\n","# Base directory path\n","base_directory_path = '/content/drive/MyDrive/207-Project/notebooks/RG/3_species/librosa_loaded_sr16000/'\n","\n","# Augmentation functions\n","def add_noise(data):\n","    noise = np.random.randn(len(data))\n","    data_noise = data + 0.005 * noise\n","    return data_noise\n","\n","def shift(data):\n","    return np.roll(data, 1600)\n","\n","# def pitch(data, sample_rate):\n","#     return librosa.effects.pitch_shift(data, sample_rate, np.random.randint(-5, 5))\n","\n","def change_volume(data):\n","    return data * np.random.uniform(low=0.75, high=1.25)\n","\n","def augment(data, sample_rate):\n","    choice = np.random.choice([1, 2, 3])\n","    if choice == 1:\n","        return add_noise(data)\n","    elif choice == 2:\n","        return shift(data)\n","    elif choice == 3:\n","        return change_volume(data)\n","    else:\n","        return data\n","\n","# Function to extract 5-second  chunks from audio\n","def extract_5sec_chunks(\n","    audio_array: np.ndarray,\n","    window_size_s: float = 5.0,\n","    hop_size_s: float = 2.5, #(with overlap)\n","    sample_rate=16000,\n","    augment_ratio=0.3\n",") -> np.ndarray:\n","    # Augment data if random value is less than augment_ratio\n","    if random.random() < augment_ratio:\n","        audio_array = augment(audio_array, sample_rate)\n","\n","    frame_length = int(window_size_s * sample_rate)\n","    frame_step = int(hop_size_s * sample_rate)\n","    framed_audio = tf.signal.frame(audio_array, frame_length, frame_step, pad_end=False)\n","\n","    return framed_audio\n","\n"]},{"cell_type":"code","source":["# Load metadata\n","dataset_path = '/content/drive/MyDrive/207-Project/notebooks/RG/3_species/'\n","metadata_path = os.path.join(dataset_path, \"train_val.csv\")\n","metadata_df = pd.read_csv(metadata_path)\n","\n","# Create a dictionary to map filenames to labels\n","labels_dict = metadata_df.set_index('filename_npy')['primary_label'].to_dict()\n","\n","# Get unique filenames from the metadata\n","filenames = set(base_directory_path + '/' + metadata_df['filename_npy'].unique())\n","\n","# Split train and validation data\n","train_df = metadata_df[metadata_df['data'] == 'train']\n","validate_df = metadata_df[metadata_df['data'] == 'val']\n","\n","# Load all train audio data one time\n","train_audios = []\n","for filename in train_df['filename_npy']:\n","    audio = np.load('/content/drive/MyDrive/207-Project/data/train/librosa_loaded/' + filename)\n","    train_audios.append(audio)\n","\n","# Load all validate audio data one time\n","val_audios = []\n","for filename in validate_df['filename_npy']:\n","    audio = np.load('/content/drive/MyDrive/207-Project/data/train/librosa_loaded/' + filename)\n","    val_audios.append(audio)\n","\n","#Initialize an empty list to store the chunk data for training data\n","train_chunks = []\n","for audio in train_audios:\n","    train_chunks.append(extract_5sec_chunks(audio))\n","\n","#Initialize an empty list to store the chunk data for VALIDATION data\n","val_chunks = []\n","for audio in val_audios:\n","    val_chunks.append(extract_5sec_chunks(audio))\n","\n","#add chunks to training data\n","train_df['audio_chunks'] = train_chunks\n","\n","#add chunks to validation data\n","validate_df['audio_chunks'] = val_chunks\n","\n","#add chunks to trainig data\n","train_df['audio_chunks'] = train_chunks\n","train_df.head()\n","train_df = train_df.sample(frac=1, random_state=1234)\n","\n","#add chunks to validation data\n","validate_df['audio_chunks'] = val_chunks\n","validate_df.head()\n","validate_df = validate_df.sample(frac=1, random_state=1234)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":652},"id":"_g1Xmh5Uwk7m","executionInfo":{"status":"error","timestamp":1690854968020,"user_tz":240,"elapsed":26044,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"ae603532-d50c-40c3-e266-16a6963b0d59"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-b89cd4233bcd>:39: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_df['audio_chunks'] = train_chunks\n","<ipython-input-6-b89cd4233bcd>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  validate_df['audio_chunks'] = val_chunks\n","<ipython-input-6-b89cd4233bcd>:45: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_df['audio_chunks'] = train_chunks\n","<ipython-input-6-b89cd4233bcd>:50: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  validate_df['audio_chunks'] = val_chunks\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-b89cd4233bcd>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#convert to X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#convert to X and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mfcc_chunks' is not defined"]}]},{"cell_type":"code","source":["def mfcc_chunks(dataframe: pd.DataFrame, sample_rate=16000, n_mfcc=13, n_fft=2048) -> tuple[np.ndarray, np.ndarray]:\n","    y = []\n","    X = []\n","\n","    for i, row in dataframe.iterrows():\n","      label = row['primary_label']\n","      tensor_5sec = row['audio_chunks']\n","\n","      for each in tensor_5sec:\n","        y.append(label)\n","        each = np.array(each)\n","        X_mfcc = mfcc(y=each, sr=sample_rate)\n","        X.append(X_mfcc)\n","\n","    assert len(y) == len(X)\n","\n","    y = np.array(y)\n","    X = np.array(X)\n","\n","    return X, y\n","\n"],"metadata":{"id":"H9n6Dl8n05Kw","executionInfo":{"status":"ok","timestamp":1690855256177,"user_tz":240,"elapsed":246,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","#convert to X and y\n","X_train, y_train = mfcc_chunks(train_df)\n","\n","#convert to X and y\n","X_val, y_val = mfcc_chunks(validate_df)\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_val shape:\", X_val.shape)\n","print(\"y_val shape:\", y_val.shape)\n","print(train_df['primary_label'].unique())\n","\n","# Save data to JSON files\n","X_train_list = X_train.tolist()\n","y_train_list = y_train.tolist()\n","X_val_list = X_val.tolist()\n","y_val_list = y_val.tolist()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"te6zOck9zBpe","executionInfo":{"status":"error","timestamp":1690855493579,"user_tz":240,"elapsed":207339,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}},"outputId":"5a84d1b4-3834-4524-ee76-fa1af14bb163"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (7889, 20, 157)\n","y_train shape: (7889,)\n","X_val shape: (3121, 20, 157)\n","y_val shape: (3121,)\n","['comsan' 'eaywag1' 'barswa']\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-9a46d45149bd>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Save data to JSON files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/My-207/X_train_mfcc_aug.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/My-207/y_train_mfcc_aug.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"]}]},{"cell_type":"code","source":["import json\n","# Save data to JSON files\n","with open('/content/drive/MyDrive/My-207/X_train_mfcc_aug.json', 'w') as file:\n","    json.dump(X_train_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_train_mfcc_aug.json', 'w') as file:\n","    json.dump(y_train_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/X_val_mfcc_aug.json', 'w') as file:\n","    json.dump(X_val_list, file)\n","\n","with open('/content/drive/MyDrive/My-207/y_val_mfcc_aug.json', 'w') as file:\n","    json.dump(y_val_list, file)\n"],"metadata":{"id":"85hCnGi22NZw","executionInfo":{"status":"ok","timestamp":1690855690379,"user_tz":240,"elapsed":72971,"user":{"displayName":"Amina Alavi","userId":"02052827403344407239"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IoRzqKOJzChF"},"execution_count":null,"outputs":[]}]}